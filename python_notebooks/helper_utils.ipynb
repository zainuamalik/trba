{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COPY FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define source and destination directories\n",
    "source_folder = \"/home/af-ml-dev/JFreaks/OCR/EasyOCR/deep-text-recognition-benchmark/datasets/combined_captchas\"\n",
    "destination_folder = \"/home/af-ml-dev/JFreaks/OCR/EasyOCR/deep-text-recognition-benchmark/test_img\"\n",
    "\n",
    "# Ensure the destination folder exists\n",
    "os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "# Copy all files from source to destination\n",
    "for filename in os.listdir(source_folder)[:10]:\n",
    "    source_path = os.path.join(source_folder, filename)\n",
    "    destination_path = os.path.join(destination_folder, filename)\n",
    "\n",
    "    # Check if it's a file before copying\n",
    "    if os.path.isfile(source_path):\n",
    "        shutil.copy2(source_path, destination_path)  # copy2 preserves metadata (timestamps)\n",
    "        print(f\"Copied: {source_path} -> {destination_path}\")\n",
    "\n",
    "print(\"All files have been copied.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAMPLE FROM MULTIPLE DATASETS AND COMBINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "def sample_dataset_with_unique(datasets, output_dir, num_samples_list):\n",
    "    \"\"\"\n",
    "    Samples a fixed number of images from each dataset, shuffles them, and saves to an output directory.\n",
    "    Duplicates are skipped, and if not enough unique images are found, a message will indicate how many were saved.\n",
    "    The images are saved with their original filenames.\n",
    "\n",
    "    Args:\n",
    "        datasets (list): List of paths to the datasets.\n",
    "        output_dir (str): Path to save the sampled and shuffled dataset.\n",
    "        num_samples_list (list): List of numbers indicating how many images to sample from each dataset.\n",
    "                                 Must match the number of datasets.\n",
    "    \"\"\"\n",
    "    if len(datasets) != len(num_samples_list):\n",
    "        raise ValueError(\"Number of datasets must match number of sample counts.\")\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    all_samples = []\n",
    "    total_saved = 0  # Total counter for images saved across all datasets\n",
    "\n",
    "    for dataset, num_samples in zip(datasets, num_samples_list):\n",
    "        print(f\"Processing dataset: {dataset} with {num_samples} images to sample.\")\n",
    "        images = [file for file in os.listdir(dataset) if file.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "        # Ensure that we do not sample more images than are available\n",
    "        if num_samples > len(images):\n",
    "            raise ValueError(f\"Requested more samples ({num_samples}) than available images in dataset ({len(images)}).\")\n",
    "\n",
    "        unique_images = set()  # Set to track unique images\n",
    "        successfully_saved = 0  # Counter for successfully saved unique images\n",
    "\n",
    "        while successfully_saved < num_samples and images:\n",
    "            image = random.choice(images)\n",
    "            if image not in unique_images:\n",
    "                unique_images.add(image)\n",
    "                all_samples.append((os.path.join(dataset, image), image))\n",
    "                successfully_saved += 1\n",
    "            else:\n",
    "                # If image is a duplicate, try another image\n",
    "                continue\n",
    "\n",
    "            # If we couldn't find enough unique images, notify user\n",
    "            if successfully_saved < num_samples and not images:\n",
    "                print(f\"Warning: Could not find enough unique images in {dataset}. Only {successfully_saved} images were saved.\")\n",
    "                break\n",
    "\n",
    "        total_saved += successfully_saved\n",
    "        print(f\"Saved {successfully_saved} images from {dataset}.\")\n",
    "\n",
    "    # Shuffle all samples\n",
    "    random.shuffle(all_samples)\n",
    "\n",
    "    # Copy sampled and shuffled images to output directory with original filenames\n",
    "    for i, (src_path, original_name) in enumerate(all_samples, start=1):\n",
    "        shutil.copy(src_path, os.path.join(output_dir, original_name))\n",
    "\n",
    "    print(f\"Sampled and shuffled dataset saved to: {output_dir}\")\n",
    "    print(f\"Total images saved across all datasets: {total_saved}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    \"/home/af-ml-dev/JFreaks/OCR/EasyOCR/deep-text-recognition-benchmark/datasets/hugging_face/captchas/nischayS/test\", #8000\n",
    "    \"/home/af-ml-dev/JFreaks/OCR/EasyOCR/deep-text-recognition-benchmark/datasets/kaggle/fanbyprinciple/data\", #8000\n",
    "    \"/home/af-ml-dev/JFreaks/OCR/EasyOCR/deep-text-recognition-benchmark/datasets/kaggle/aadhavvignesh/data\", #10000\n",
    "    \"/home/af-ml-dev/JFreaks/OCR/EasyOCR/deep-text-recognition-benchmark/datasets/kaggle/huthay\", #10000\n",
    "    \"/home/af-ml-dev/JFreaks/OCR/EasyOCR/deep-text-recognition-benchmark/datasets/kaggle/sandeep1507/data\", #15000\n",
    "    \"/home/af-ml-dev/JFreaks/OCR/EasyOCR/deep-text-recognition-benchmark/datasets/hugging_face/captchas/nischay\", #15000\n",
    "    \"/home/af-ml-dev/JFreaks/OCR/EasyOCR/deep-text-recognition-benchmark/datasets/kaggle/akashguna/data\", #15000\n",
    "    \"/home/af-ml-dev/JFreaks/OCR/EasyOCR/deep-text-recognition-benchmark/datasets/kaggle/khushipitroda/data\", #15000\n",
    "    \"/home/af-ml-dev/JFreaks/OCR/EasyOCR/deep-text-recognition-benchmark/datasets/kaggle/kiran\", #15000\n",
    "    \"/home/af-ml-dev/JFreaks/OCR/EasyOCR/deep-text-recognition-benchmark/datasets/hugging_face/captchas/hammer888\", #25000\n",
    "    \"/home/af-ml-dev/JFreaks/OCR/EasyOCR/deep-text-recognition-benchmark/datasets/kaggle/parasam/data\", #25000\n",
    "    \"/home/af-ml-dev/JFreaks/OCR/EasyOCR/deep-text-recognition-benchmark/datasets/kaggle/jassoncarvalho/data\" #25000\n",
    "    \n",
    "]\n",
    "output_dir = \"/home/af-ml-dev/JFreaks/OCR/EasyOCR/deep-text-recognition-benchmark/datasets/combined_captchas\"\n",
    "num_samples_list = [8000, 8000, 10000, 9000, 15000, 15000, 15000, 15000, 15000, 25000, 25000, 25000]   # Specify the number of samples per dataset\n",
    "sample_dataset_with_unique(datasets, output_dir, num_samples_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONVERT ALL IMAGES TO SAME EXTENSION (PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, UnidentifiedImageError  # Import the error\n",
    "import os\n",
    "\n",
    "def convert_images_in_folder(directory, target_extension='png'):\n",
    "    \"\"\"\n",
    "    Converts all images in a directory to the target extension and replaces the original files.\n",
    "    At the end, lists files that couldn't be converted.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        raise ValueError(f\"The directory {directory} does not exist.\")\n",
    "    \n",
    "    failed_conversions = []  # List to store files that couldn't be converted\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        \n",
    "        if os.path.isfile(file_path):\n",
    "            try:\n",
    "                # Try to open the image file\n",
    "                with Image.open(file_path) as img:\n",
    "                    # Get the file extension (lowercase)\n",
    "                    file_extension = filename.split('.')[-1].lower()\n",
    "\n",
    "                    # Skip if already in the target format\n",
    "                    if file_extension == target_extension.lower():\n",
    "                        continue\n",
    "                    \n",
    "                    # Set the new filename with the target extension\n",
    "                    new_file_path = f\"{os.path.splitext(file_path)[0]}.{target_extension.lower()}\"\n",
    "\n",
    "                    # Save the image with the new extension, replacing the original file\n",
    "                    img.save(new_file_path)\n",
    "                    os.remove(file_path)  # Remove the original file\n",
    "                    print(f\"Converted and replaced {filename} with {os.path.basename(new_file_path)}\")\n",
    "            except (UnidentifiedImageError, OSError) as e:\n",
    "                # Add the file to the failed conversions list\n",
    "                failed_conversions.append(filename)\n",
    "                print(f\"Skipping {filename}: {e}\")\n",
    "    \n",
    "    print(\"\\nImage conversion complete.\")\n",
    "    \n",
    "    # Print any files that couldn't be converted\n",
    "    if failed_conversions:\n",
    "        print(\"The following files could not be converted:\")\n",
    "        for failed_file in failed_conversions:\n",
    "            print(f\" - {failed_file}\")\n",
    "    else:\n",
    "        print(\"All files were successfully converted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image conversion complete.\n",
      "All files were successfully converted.\n"
     ]
    }
   ],
   "source": [
    "input_dir = '/home/af-ml-dev/JFreaks/OCR/EasyOCR/deep-text-recognition-benchmark/datasets/combined_captchas_aug/combined_captchas'\n",
    "convert_images_in_folder(input_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPLIT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 40000\n",
      "Train images: 32000\n",
      "Test images: 6000\n",
      "Validation images: 2000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the directory where the images are located\n",
    "image_dir = '/home/af-ml-dev/JFreaks/OCR/EasyOCR/deep-text-recognition-benchmark/datasets/combined_captchas_aug/combined_captchas'\n",
    "train_dir = '/home/af-ml-dev/JFreaks/OCR/EasyOCR/deep-text-recognition-benchmark/datasets/combined_captchas_aug/trainH'\n",
    "test_dir = '/home/af-ml-dev/JFreaks/OCR/EasyOCR/deep-text-recognition-benchmark/datasets/combined_captchas_aug/testH'\n",
    "val_dir = '/home/af-ml-dev/JFreaks/OCR/EasyOCR/deep-text-recognition-benchmark/datasets/combined_captchas_aug/validH'\n",
    "\n",
    "# Create directories for train, test, and validation sets if they don't exist\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "# List all image files in the directory\n",
    "image_files = [f for f in os.listdir(image_dir) if f.endswith(('jpg', 'jpeg', 'png', 'bmp', 'gif', 'tiff'))]\n",
    "\n",
    "#slice of dataset CHANGE LATER\n",
    "image_files= image_files[:40000]\n",
    "\n",
    "# Split the images into train (80%) and temp (test + validation 20%)\n",
    "train_images, temp_images = train_test_split(image_files, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the temp set into test (15%) and validation (5%) sets\n",
    "test_images, val_images = train_test_split(temp_images, test_size=0.25, random_state=42)  # 0.25 of 0.2 = 5%\n",
    "\n",
    "# Function to move images to the respective directories\n",
    "def move_images(image_list, destination_dir):\n",
    "    for image in image_list:\n",
    "        src_path = os.path.join(image_dir, image)\n",
    "        dest_path = os.path.join(destination_dir, image)\n",
    "        shutil.move(src_path, dest_path)\n",
    "\n",
    "# Move the images to the appropriate directories\n",
    "move_images(train_images, train_dir)\n",
    "move_images(test_images, test_dir)\n",
    "move_images(val_images, val_dir)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Total images: {len(image_files)}\")\n",
    "print(f\"Train images: {len(train_images)}\")\n",
    "print(f\"Test images: {len(test_images)}\")\n",
    "print(f\"Validation images: {len(val_images)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APPLY AUGMENTATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename images and create gt.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def rename_images_and_create_gt(input_folder, output_folder, gt_file_path):\n",
    "    \"\"\"\n",
    "    Renames augmented CAPTCHA images and generates a ground truth file.\n",
    "    \n",
    "    Args:\n",
    "        input_folder (str): Path to the folder containing augmented images.\n",
    "        output_folder (str): Path to save the renamed images.\n",
    "        gt_file_path (str): Path to save the ground truth file (gt.txt).\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Open the ground truth file in write mode\n",
    "    with open(gt_file_path, 'w') as gt_file:\n",
    "        # Initialize a counter for new image names\n",
    "        image_counter = 1\n",
    "\n",
    "        # Loop through the images in the input folder\n",
    "        for img_name in os.listdir(input_folder):\n",
    "            img_path = os.path.join(input_folder, img_name)\n",
    "\n",
    "            if os.path.isfile(img_path) and img_name.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                # Extract the annotation part from the filename (without extension)\n",
    "                annotation = os.path.splitext(img_name.split('_')[0])[0]  # Remove extension from annotation\n",
    "\n",
    "                # Generate the new filename (image_1.extension, image_2.extension, etc.)\n",
    "                new_img_name = f\"image_{image_counter}{os.path.splitext(img_name)[1]}\"\n",
    "                new_img_path = os.path.join(output_folder, new_img_name)\n",
    "\n",
    "                # Rename the image and move/copy it to the new folder\n",
    "                shutil.move(img_path, new_img_path)\n",
    "\n",
    "                # Write the new filename and its annotation to the gt.txt file\n",
    "                gt_file.write(f\"{new_img_name} {annotation}\\n\")\n",
    "\n",
    "                # Increment the counter for the next image\n",
    "                image_counter += 1\n",
    "\n",
    "    print(f\"Images have been renamed and saved to {output_folder}. Ground truth file saved to {gt_file_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images have been renamed and saved to /home/af-ml-dev/JFreaks/OCR/EasyOCR/deep-aug/deep-text-recognition-benchmark/captcha_batch1/data. Ground truth file saved to /home/af-ml-dev/JFreaks/OCR/EasyOCR/deep-aug/deep-text-recognition-benchmark/captcha_batch1/gt.txt.\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "input_folder = '/home/af-ml-dev/JFreaks/OCR/EasyOCR/deep-aug/deep-text-recognition-benchmark/captcha_batch1/fixed'  # Path to the folder with augmented images\n",
    "output_folder = '/home/af-ml-dev/JFreaks/OCR/EasyOCR/deep-aug/deep-text-recognition-benchmark/captcha_batch1/data'    # Path to save renamed images\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "gt_file_path = '/home/af-ml-dev/JFreaks/OCR/EasyOCR/deep-aug/deep-text-recognition-benchmark/captcha_batch1/gt.txt'     # Path to save ground truth file\n",
    "\n",
    "rename_images_and_create_gt(input_folder, output_folder, gt_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIX FILENAMES / EXTRACT ANNOTATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotations_from_txt_to_filename(dataset_path, txt_file, output_dir):\n",
    "    \"\"\"\n",
    "    Reads annotations from a TXT file and updates filenames to include the annotations.\n",
    "\n",
    "    Args:\n",
    "        dataset_path (str): Path to the dataset containing images.\n",
    "        txt_file (str): Path to the TXT file with annotations.\n",
    "        output_dir (str): Directory to save updated images with annotations in filenames.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    with open(txt_file, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(maxsplit=1)\n",
    "            if len(parts) < 2:\n",
    "                continue\n",
    "            image_name, annotation = parts[0], parts[1]\n",
    "            image_path = os.path.join(dataset_path, image_name)\n",
    "            if os.path.exists(image_path):\n",
    "                new_filename = f\"{annotation}.png\"\n",
    "                shutil.copy(image_path, os.path.join(output_dir, new_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{irrelevant}_{annotation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_filenames_irrelevant_prefix(dataset_path, output_dir):\n",
    "    \"\"\"\n",
    "    Fixes filenames in the format `{irrelevant}_{annotation}` by extracting the annotation.\n",
    "\n",
    "    Args:\n",
    "        dataset_path (str): Path to the dataset containing images.\n",
    "        output_dir (str): Directory to save updated images with fixed filenames.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for file in os.listdir(dataset_path):\n",
    "        if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            filename, ext = os.path.splitext(file)\n",
    "            if '_' in filename:\n",
    "                annotation = filename.split('_')[-1]\n",
    "                new_filename = f\"{annotation}.png\"\n",
    "                shutil.copy(os.path.join(dataset_path, file), os.path.join(output_dir, new_filename))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{annotation}_{irrelevant}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_filenames_irrelevant_suffix(dataset_path, output_dir):\n",
    "    \"\"\"\n",
    "    Fixes filenames in the format `{annotation}_{irrelevant}` by extracting the annotation.\n",
    "\n",
    "    Args:\n",
    "        dataset_path (str): Path to the dataset containing images.\n",
    "        output_dir (str): Directory to save updated images with fixed filenames.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for file in os.listdir(dataset_path):\n",
    "        if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            filename, ext = os.path.splitext(file)\n",
    "            if '_' in filename:\n",
    "                annotation = filename.split('_')[0]\n",
    "                new_filename = f\"{annotation}.png\"\n",
    "                shutil.copy(os.path.join(dataset_path, file), os.path.join(output_dir, new_filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "data_path= '/home/af-ml-dev/JFreaks/OCR/EasyOCR/deep-aug/deep-text-recognition-benchmark/captcha_batch1'\n",
    "out_path= '/home/af-ml-dev/JFreaks/OCR/EasyOCR/deep-aug/deep-text-recognition-benchmark/captcha_batch1/fixed'\n",
    "\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "fix_filenames_irrelevant_suffix(dataset_path=data_path, output_dir=out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
