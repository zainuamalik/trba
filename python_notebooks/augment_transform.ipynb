{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import random\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Safe mild augmentations: Tight constraints for scaling, rotation, and translation\n",
    "MILD_AUGMENTATIONS = A.Compose([\n",
    "    A.Affine(\n",
    "        scale=(0.98, 1.02),  # Very tight scaling range\n",
    "        translate_percent=(-0.03, 0.03),  # Slight translation limits\n",
    "        rotate=(-3, 3),  # Tight rotation limits\n",
    "        shear=(-2, 2),  # Minimal shear\n",
    "        p=0.7\n",
    "    ),\n",
    "    A.GaussianBlur(blur_limit=(3, 5), p=0.4),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "    A.RandomSizedCrop(min_max_height=(100, 200), size=(64, 256), p=0.5),  # Controlled crop size\n",
    "])\n",
    "\n",
    "# Safe moderate augmentations with additional safety for larger images\n",
    "MODERATE_AUGMENTATIONS = A.Compose([\n",
    "    A.Affine(\n",
    "        scale=(0.95, 1.05),  # Slight scaling range\n",
    "        translate_percent=(-0.02, 0.02),  # Small translation\n",
    "        rotate=(-5, 5),  # Slight rotation\n",
    "        shear=(-3, 3),  # Minimal shear\n",
    "        p=0.7\n",
    "    ),\n",
    "    A.GaussianBlur(blur_limit=(3, 5), p=0.4),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),\n",
    "])\n",
    "\n",
    "EXTREME_AUGMENTATIONS = A.Compose([\n",
    "    A.Affine(\n",
    "        scale=(0.85, 1.15),  # Controlled scaling range\n",
    "        translate_percent=(-0.05, 0.05),  # Small translations\n",
    "        rotate=(-15, 15),  # Moderate rotation range\n",
    "        shear=(-10, 10),  # Limited shear\n",
    "        p=0.9\n",
    "    ),\n",
    "    A.MotionBlur(blur_limit=7, p=0.6),\n",
    "    A.GaussNoise(std_range=(0.2, 0.4), p=0.3),\n",
    "])\n",
    "\n",
    "# Balanced Sampling Function\n",
    "def get_augmentation_type():\n",
    "    \"\"\"Randomly choose an augmentation category based on probability.\"\"\"\n",
    "    return random.choices(\n",
    "        [\"mild\", \"moderate\", \"extreme\"], \n",
    "        weights=[0.5, 0.35, 0.15],  # 50% mild, 35% moderate, 15% extreme\n",
    "        k=1\n",
    "    )[0]\n",
    "\n",
    "# Apply augmentations\n",
    "def apply_augmentations(image, category):\n",
    "    \"\"\"Apply augmentation based on the selected category.\"\"\"\n",
    "    if category == \"mild\":\n",
    "        transform = MILD_AUGMENTATIONS\n",
    "    elif category == \"moderate\":\n",
    "        transform = MODERATE_AUGMENTATIONS\n",
    "    else:\n",
    "        transform = EXTREME_AUGMENTATIONS\n",
    "\n",
    "    augmented_image = transform(image=image)[\"image\"]\n",
    "\n",
    "    # After augmentation, pad the image to ensure no clipping\n",
    "    augmented_image = pad_image(augmented_image, image.shape[0], image.shape[1])\n",
    "    \n",
    "    return augmented_image\n",
    "\n",
    "# Function to compute the bounding box of the non-black areas (content)\n",
    "def get_content_bounding_box(image):\n",
    "    \"\"\"Compute the bounding box of the content in the image (non-black areas).\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, threshold = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n",
    "    coords = np.column_stack(np.where(threshold > 0))\n",
    "\n",
    "    if len(coords) == 0:\n",
    "        return (0, 0, 0, 0)\n",
    "\n",
    "    top_left = coords.min(axis=0)\n",
    "    bottom_right = coords.max(axis=0)\n",
    "\n",
    "    return top_left[0], top_left[1], bottom_right[0], bottom_right[1]\n",
    "\n",
    "# Function to pad the image to the original size after transformation if needed\n",
    "def pad_image(image, original_height, original_width):\n",
    "    \"\"\"Ensure the image is padded back to the original dimensions.\"\"\"\n",
    "    current_height, current_width = image.shape[:2]\n",
    "\n",
    "    # Add padding to ensure the image dimensions match the original\n",
    "    pad_top = max(0, (original_height - current_height) // 2)\n",
    "    pad_bottom = max(0, original_height - current_height - pad_top)\n",
    "    pad_left = max(0, (original_width - current_width) // 2)\n",
    "    pad_right = max(0, original_width - current_width - pad_left)\n",
    "\n",
    "    padded_image = cv2.copyMakeBorder(\n",
    "        image, pad_top, pad_bottom, pad_left, pad_right, cv2.BORDER_CONSTANT, value=(0, 0, 0)\n",
    "    )\n",
    "\n",
    "    return padded_image\n",
    "\n",
    "# Apply augmentations safely based on bounding box tracking\n",
    "def apply_safe_augmentation(image, transform, original_height, original_width):\n",
    "    \"\"\"Apply augmentation and ensure text stays within the image bounds.\"\"\"\n",
    "    # Get the content bounding box of the original image\n",
    "    orig_top, orig_left, orig_bottom, orig_right = get_content_bounding_box(image)\n",
    "\n",
    "    # Apply transformation\n",
    "    augmented_image = transform(image=image)[\"image\"]\n",
    "\n",
    "    # Get the new bounding box of the transformed image\n",
    "    aug_top, aug_left, aug_bottom, aug_right = get_content_bounding_box(augmented_image)\n",
    "\n",
    "    # Ensure the content is not moved outside of the image bounds\n",
    "    if aug_top < 0 or aug_left < 0 or aug_bottom > original_height or aug_right > original_width:\n",
    "        augmented_image = pad_image(augmented_image, original_height, original_width)\n",
    "    \n",
    "    return augmented_image\n",
    "\n",
    "# Apply mild, moderate, and extreme augmentations\n",
    "def augment_single_image(image_path, output_folder, num_variations=3):\n",
    "    \"\"\"\n",
    "    Augment a single image and save outputs.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image file.\n",
    "        output_folder (str): Path to save augmented images.\n",
    "        num_variations (int): Number of augmented versions per image.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error: Failed to load {image_path}\")\n",
    "        return\n",
    "    \n",
    "    base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    original_height, original_width = image.shape[:2]\n",
    "\n",
    "    # Generate augmented versions and save them\n",
    "    for i in range(num_variations):\n",
    "        category = get_augmentation_type()\n",
    "        \n",
    "        # Select appropriate augmentation based on category\n",
    "        if category == \"mild\":\n",
    "            transform = MILD_AUGMENTATIONS\n",
    "        elif category == \"moderate\":\n",
    "            transform = MODERATE_AUGMENTATIONS\n",
    "        else:\n",
    "            transform = EXTREME_AUGMENTATIONS\n",
    "        \n",
    "        augmented_image = apply_safe_augmentation(image, transform, original_height, original_width)\n",
    "        \n",
    "        output_path = os.path.join(output_folder, f\"{base_name}_{category}_{i}.png\")\n",
    "        cv2.imwrite(output_path, augmented_image)\n",
    "\n",
    "# Function to process an entire folder for augmentations\n",
    "def augment_dataset(input_path, output_folder, num_variations=3):\n",
    "    \"\"\"\n",
    "    Augment images in a folder or a single image file.\n",
    "    \n",
    "    Args:\n",
    "        input_path (str): Path to the folder or single image.\n",
    "        output_folder (str): Path to save augmented images.\n",
    "        num_variations (int): Number of augmented versions per image.\n",
    "    \"\"\"\n",
    "    if os.path.isfile(input_path):\n",
    "        # If input is a single image\n",
    "        print(f\"Processing single image: {input_path}\")\n",
    "        augment_single_image(input_path, output_folder, num_variations)\n",
    "    elif os.path.isdir(input_path):\n",
    "        # If input is a folder\n",
    "        print(f\"Processing folder: {input_path}\")\n",
    "        images = [f for f in os.listdir(input_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        \n",
    "        for img_name in tqdm(images, desc=\"Augmenting Images\"):\n",
    "            img_path = os.path.join(input_path, img_name)\n",
    "            augment_single_image(img_path, output_folder, num_variations)\n",
    "    else:\n",
    "        print(\"Error: Input path is neither a valid file nor a directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder: /home/af-ml-dev/JFreaks/OCR/EasyOCR/deep-text-recognition-benchmark/scraped_captchas_train_aug/data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting Images: 100%|██████████| 850/850 [00:08<00:00, 104.74it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run Augmentation on a dataset folder OR a single image\n",
    "input_path = \"/home/af-ml-dev/JFreaks/OCR/EasyOCR/deep-text-recognition-benchmark/scraped_captchas_train_aug/data\"  # Change to your file or folder\n",
    "output_folder = \"/home/af-ml-dev/JFreaks/OCR/EasyOCR/deep-text-recognition-benchmark/scraped_captchas_train_aug/data\"  # Change to your output folder\n",
    "augment_dataset(input_path, output_folder, num_variations=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIX FILENAMES AND gt.txt AFTER APPLYING AUGMENTATIONS (only works if image filenames are in the format: image_1.png etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renaming and gt.txt update completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Paths\n",
    "image_folder = \"/home/af-ml-dev/JFreaks/OCR/EasyOCR/deep-text-recognition-benchmark/scraped_captchas_train_aug/data\"  # Folder containing images\n",
    "gt_file = \"/home/af-ml-dev/JFreaks/OCR/EasyOCR/deep-text-recognition-benchmark/scraped_captchas_train_aug/gt.txt\"  # Ground truth file\n",
    "\n",
    "# Read the gt.txt file and store labels in a dictionary\n",
    "labels_dict = {}\n",
    "with open(gt_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split(\" \", 1)\n",
    "        if len(parts) == 2:\n",
    "            filename, label = parts\n",
    "            labels_dict[filename] = label\n",
    "\n",
    "# Get the highest numbered original image\n",
    "original_images = [fname for fname in os.listdir(image_folder) if re.match(r\"image_\\d+\\.png\", fname)]\n",
    "highest_number = max(int(re.search(r\"image_(\\d+)\\.png\", img).group(1)) for img in original_images)\n",
    "\n",
    "# Process augmented images\n",
    "new_gt_entries = []\n",
    "for fname in os.listdir(image_folder):\n",
    "    match = re.match(r\"(image_\\d+)_(mild|moderate|extreme)_\\d+\\.png\", fname)\n",
    "    if match:\n",
    "        original_base = match.group(1) + \".png\"  # Extract original image filename\n",
    "        if original_base in labels_dict:\n",
    "            highest_number += 1\n",
    "            new_filename = f\"image_{highest_number}.png\"\n",
    "            os.rename(os.path.join(image_folder, fname), os.path.join(image_folder, new_filename))\n",
    "            new_gt_entries.append(f\"{new_filename} {labels_dict[original_base]}\")\n",
    "\n",
    "# Append new entries to gt.txt\n",
    "with open(gt_file, \"a\") as f:\n",
    "    f.write(\"\\n\".join(new_gt_entries) + \"\\n\")\n",
    "\n",
    "print(\"Renaming and gt.txt update completed successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
